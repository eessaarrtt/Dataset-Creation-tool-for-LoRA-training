#!/usr/bin/env python3
"""
Dataset Creation Bulk - Python –∞–Ω–∞–ª–æ–≥ Make.com workflow
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ, –≤—ã–±–æ—Ä –º–µ–∂–¥—É Gemini/OpenAI –∏ Wavespeed
"""

import os
import json
import base64
import argparse
import shutil
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import mimetypes
import zipfile

# –ò–º–ø–æ—Ä—Ç —Å–∏—Å—Ç–µ–º—ã –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏
try:
    from i18n import get_i18n, set_language
    I18N_AVAILABLE = True
except ImportError:
    I18N_AVAILABLE = False
    # –ü—Ä–æ—Å—Ç–æ–π fallback –µ—Å–ª–∏ i18n –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω
    def get_i18n():
        class SimpleI18n:
            def t(self, key, **kwargs):
                return key
        return SimpleI18n()
    def set_language(lang):
        return True

# AI providers
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# HTTP requests
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry


class Config:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ—Ñ–∏–ª–µ–π"""
    
    PROFILES_DIR = "profiles"
    
    def __init__(self, config_file: Optional[str] = None, profile_name: Optional[str] = None):
        self.config_file = config_file or "config.json"
        self.profile_name = profile_name
        self.profiles_dir = Path(self.PROFILES_DIR)
        self.profiles_dir.mkdir(exist_ok=True)
        self.load_config()
    
    def load_config(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—ã–π config.json (–ø—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º –∏ API –∫–ª—é—á–∏)
        if os.path.exists(self.config_file):
            with open(self.config_file, 'r', encoding='utf-8') as f:
                base_config = json.load(f)
        else:
            base_config = self.get_minimal_config()
            self.save_base_config(base_config)
        
        # –ü—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º (–≤—Å–µ–≥–¥–∞ –∏–∑ –±–∞–∑–æ–≤–æ–≥–æ config.json)
        self.influencer_ref_folder = base_config.get('influencer_ref_folder', './Influencer Reference Images')
        self.sample_dataset_folder = base_config.get('sample_dataset_folder', './Sample Dataset')
        self.output_folder = base_config.get('output_folder', './output')
        
        # –õ–∏–º–∏—Ç—ã (–∏–∑ –±–∞–∑–æ–≤–æ–≥–æ config)
        self.limit_ref_images = base_config.get('limit_ref_images', 10)
        self.limit_sample_images = base_config.get('limit_sample_images', 10)
        
        # API –∫–ª—é—á–∏ –∏–∑ config.json (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        self.gemini_api_key = base_config.get('gemini_api_key', '')
        self.openai_api_key = base_config.get('openai_api_key', '')
        self.wavespeed_api_key = base_config.get('wavespeed_api_key', '')
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—Ä–æ—Ñ–∏–ª—å, –∑–∞–≥—Ä—É–∂–∞–µ–º –µ–≥–æ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–ª—é—á–∏ –µ—Å–ª–∏ –æ–Ω–∏ —Ç–∞–º –µ—Å—Ç—å)
        if self.profile_name:
            self.load_from_profile(self.profile_name)
        else:
            # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤/–º–æ–¥–µ–ª–µ–π
            self.set_minimal_defaults(base_config)
    
    def set_minimal_defaults(self, base_config: Dict):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ)"""
        # AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤
        self.ai_provider = None
        
        # –ú–æ–¥–µ–ª–∏ (–∫–ª—é—á–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ config.json)
        self.gemini_model = 'gemini-2.5-flash'
        self.openai_model = 'gpt-5-mini'
        
        # Image generation –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        self.image_provider = None
        
        # Wavespeed –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∫–ª—é—á —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ config.json)
        self.wavespeed_size = '2880*4096'
        self.wavespeed_model = ''
        self.wavespeed_resolution = '1k'
        self.wavespeed_output_format = 'png'
        
        # –ü—Ä–æ–º–ø—Ç —à–∞–±–ª–æ–Ω
        self.prompt_template = 'bulk'
        
        # LoRA captions –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.trigger_name = ''
        self.generate_captions = False
        self.openai_caption_model = 'gpt-5.1'  # –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ captions (gpt-5.1 –∏–ª–∏ gpt-4o –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç vision)
    
    def load_from_profile(self, profile_name: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è"""
        profile_path = self.profiles_dir / f"{profile_name}.json"
        if not profile_path.exists():
            raise FileNotFoundError(f"–ü—Ä–æ—Ñ–∏–ª—å '{profile_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        with open(profile_path, 'r', encoding='utf-8') as f:
            profile = json.load(f)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è
        # API –∫–ª—é—á–∏ –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—é—Ç –∫–ª—é—á–∏ –∏–∑ config.json (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã)
        self.ai_provider = profile.get('ai_provider')
        if profile.get('gemini_api_key'):
            self.gemini_api_key = profile.get('gemini_api_key')
        self.gemini_model = profile.get('gemini_model', 'gemini-2.5-flash')
        if profile.get('openai_api_key'):
            self.openai_api_key = profile.get('openai_api_key')
        self.openai_model = profile.get('openai_model', 'gpt-5-mini')
        self.image_provider = profile.get('image_provider')
        if profile.get('wavespeed_api_key'):
            self.wavespeed_api_key = profile.get('wavespeed_api_key')
        self.wavespeed_size = profile.get('wavespeed_size', '2880*4096')
        self.wavespeed_model = profile.get('wavespeed_model', '')
        self.wavespeed_resolution = profile.get('wavespeed_resolution', '1k')
        self.wavespeed_output_format = profile.get('wavespeed_output_format', 'png')
        self.prompt_template = profile.get('prompt_template', 'bulk')
        self.trigger_name = profile.get('trigger_name', '')
        self.generate_captions = profile.get('generate_captions', False)
        self.openai_caption_model = profile.get('openai_caption_model', 'gpt-5.1')
        # –õ–∏–º–∏—Ç—ã –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã)
        if profile.get('limit_ref_images'):
            self.limit_ref_images = profile.get('limit_ref_images')
        if profile.get('limit_sample_images'):
            self.limit_sample_images = profile.get('limit_sample_images')
    
    def save_to_profile(self, profile_name: str, description: str = ""):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ –ø—Ä–æ—Ñ–∏–ª—å (–±–µ–∑ API –∫–ª—é—á–µ–π, –æ–Ω–∏ –≤ config.json)"""
        profile_path = self.profiles_dir / f"{profile_name}.json"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–æ—Ñ–∏–ª—å
        created_at = None
        if profile_path.exists():
            try:
                with open(profile_path, 'r', encoding='utf-8') as f:
                    existing = json.load(f)
                    created_at = existing.get('created_at', datetime.now().isoformat())
            except:
                created_at = datetime.now().isoformat()
        else:
            created_at = datetime.now().isoformat()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤/–º–æ–¥–µ–ª–µ–π, –Ω–µ API –∫–ª—é—á–∏
        # (–∫–ª—é—á–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ config.json)
        profile_data = {
            'name': profile_name,
            'description': description,
            'created_at': created_at,
            'updated_at': datetime.now().isoformat(),
            'ai_provider': self.ai_provider,
            'gemini_model': self.gemini_model,
            'openai_model': self.openai_model,
            'image_provider': self.image_provider,
            'wavespeed_size': self.wavespeed_size,
            'wavespeed_model': self.wavespeed_model,
            'wavespeed_resolution': self.wavespeed_resolution,
            'wavespeed_output_format': self.wavespeed_output_format,
            'prompt_template': self.prompt_template,
            'trigger_name': self.trigger_name,
            'generate_captions': self.generate_captions,
            'openai_caption_model': self.openai_caption_model,
            'limit_ref_images': self.limit_ref_images,
            'limit_sample_images': self.limit_sample_images,
            '_note': 'API –∫–ª—é—á–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ config.json –∏ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø—Ä–æ—Ñ–∏–ª—è—Ö'
        }
        
        with open(profile_path, 'w', encoding='utf-8') as f:
            json.dump(profile_data, f, indent=2, ensure_ascii=False)
        
        return profile_path
    
    def list_profiles(self) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π"""
        profiles = []
        if not self.profiles_dir.exists():
            return profiles
        
        for profile_file in self.profiles_dir.glob("*.json"):
            try:
                with open(profile_file, 'r', encoding='utf-8') as f:
                    profile = json.load(f)
                profiles.append({
                    'name': profile.get('name', profile_file.stem),
                    'description': profile.get('description', ''),
                    'file': profile_file.stem
                })
            except:
                continue
        
        return sorted(profiles, key=lambda x: x['name'])
    
    def get_minimal_config(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–ø—É—Ç–∏ –∏ API –∫–ª—é—á–∏)"""
        return {
            'influencer_ref_folder': './Influencer Reference Images',
            'sample_dataset_folder': './Sample Dataset',
            'output_folder': './output',
            'limit_ref_images': 10,
            'limit_sample_images': 10,
            'gemini_api_key': '',
            'openai_api_key': '',
            'wavespeed_api_key': ''
        }
    
    def save_base_config(self, config: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (—Ç–æ–ª—å–∫–æ –ø—É—Ç–∏)"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def to_dict(self) -> Dict:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        return {
            'ai_provider': self.ai_provider,
            'gemini_api_key': self.gemini_api_key,
            'gemini_model': self.gemini_model,
            'openai_api_key': self.openai_api_key,
            'openai_model': self.openai_model,
            'image_provider': self.image_provider,
            'wavespeed_api_key': self.wavespeed_api_key,
            'wavespeed_size': self.wavespeed_size,
            'wavespeed_model': self.wavespeed_model,
            'wavespeed_resolution': self.wavespeed_resolution,
            'wavespeed_output_format': self.wavespeed_output_format,
            'prompt_template': self.prompt_template,
            'limit_ref_images': self.limit_ref_images,
            'limit_sample_images': self.limit_sample_images
        }


class LocalFileManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ –≤–º–µ—Å—Ç–æ Dropbox"""
    
    @staticmethod
    def list_image_files(folder_path: str, limit: int = 10) -> List[Dict]:
        """–°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ"""
        folder = Path(folder_path)
        if not folder.exists():
            raise FileNotFoundError(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")
        
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
        files = []
        
        for file_path in folder.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in image_extensions:
                files.append({
                    'id': str(file_path),
                    'name': file_path.name,
                    'path': str(file_path),
                    'size': file_path.stat().st_size
                })
                if len(files) >= limit:
                    break
        
        return files
    
    @staticmethod
    def read_file(file_path: str) -> Tuple[bytes, str]:
        """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ –∏–º—è —Ñ–∞–π–ª–∞"""
        path = Path(file_path)
        if not path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        
        with open(path, 'rb') as f:
            data = f.read()
        
        return data, path.name
    
    @staticmethod
    def get_mime_type(file_path: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç MIME —Ç–∏–ø —Ñ–∞–π–ª–∞"""
        mime_type, _ = mimetypes.guess_type(file_path)
        return mime_type or 'image/jpeg'


class PromptGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–æ–º–ø—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—è Gemini –∏–ª–∏ OpenAI"""
    
    def __init__(self, config: Config):
        self.config = config
        self.setup_provider()
    
    def setup_provider(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä"""
        if self.config.ai_provider == 'gemini':
            if not GEMINI_AVAILABLE:
                raise ImportError("google-generativeai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install google-generativeai")
            if not self.config.gemini_api_key:
                raise ValueError("Gemini API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            genai.configure(api_key=self.config.gemini_api_key)
            self.client = genai.GenerativeModel(self.config.gemini_model)
        
        elif self.config.ai_provider == 'openai':
            if not OPENAI_AVAILABLE:
                raise ImportError("openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
            if not self.config.openai_api_key:
                raise ValueError("OpenAI API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            self.client = OpenAI(api_key=self.config.openai_api_key)
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.config.ai_provider}")
    
    def generate_prompt(self, ref_images: List[bytes], sample_image: bytes) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–±–æ–∏—Ö —à–∞–±–ª–æ–Ω–æ–≤
        # –†–∞–∑–Ω–∏—Ü–∞ —Ç–æ–ª—å–∫–æ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å Wavespeed –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        wavespeed_model = getattr(self.config, 'wavespeed_model', '')
        prompt_text = self._get_prompt_template(wavespeed_model)
        
        if self.config.ai_provider == 'gemini':
            return self._generate_with_gemini(prompt_text, ref_images, sample_image)
        else:
            return self._generate_with_openai(prompt_text, ref_images, sample_image)
    
    def _get_prompt_template(self, wavespeed_model: str = '') -> str:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å Wavespeed"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –∏ —Å–æ–∑–¥–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ–º–ø—Ç
        model_name = ""
        model_version = ""
        
        if 'seedream-v4.5' in wavespeed_model.lower() or 'seedream-v4.5' in wavespeed_model:
            model_name = "Seedream v4.5"
            model_version = "4.5"
        elif 'seedream-v4' in wavespeed_model.lower() and 'v4.5' not in wavespeed_model.lower():
            model_name = "Seedream v4.0"
            model_version = "4.0"
        elif 'nano-banana' in wavespeed_model.lower() or 'nano-banana-pro' in wavespeed_model.lower():
            model_name = "Nano Banana Pro"
            model_version = "Pro"
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º Seedream 4.0
            model_name = "Seedream v4.0"
            model_version = "4.0"
        
        return f"""You are an expert prompt engineer specializing in the {model_name} AI model. You create complete, detailed, and technically precise image generation prompts.

Primary Directive: Your task is to analyze Reference Image 3 (a complete scene) and generate a single, comprehensive prompt for {model_name}. This prompt will instruct the model on how to use a total of three reference images.

Critical Context (Non-negotiable): {model_name} will always receive 3 reference images in this specific order:
Images 1 & 2: Provide the subject's complete face structure, facial features, and identity.
Image 3: The complete scene reference (this is the image you will be given to analyze).
Your analysis must focus exclusively on Image 3. Your generated prompt must correctly instruct {model_name} on this specific 3-image workflow.

Your Generation Task:
You will be given Image 3.
You will analyze Image 3 ONLY.
You will output ONLY the complete, formatted prompt for {model_name}. Do not add any conversational preamble, explanation, or text outside the specified format.

Mandatory Output Format (Strict Template):
Use the first two reference images for the subject's complete face, features, and identity. Use reference image 3 as the complete reference for all other elements: clothing, pose, action, body type, scene composition, background environment, lighting, and overall atmosphere.

Subject details: [Describe the subject's clothing in exhaustive detail: every visible garment (e.g., shirt, jacket, trousers, dress), accessories (e.g., hat, scarf, belt, bag), jewelry (e.g., necklace, earrings, rings, watch), and footwear. Specify colors, patterns, textures (e.g., denim, silk, wool, leather), cuts (e.g., loose-fitting, tailored), and styles (e.g., formal, casual, athletic)]. [Describe the exact pose: sitting, standing, leaning. Detail the position of the torso, arms (e.g., folded, extended, one hand in pocket), legs (e.g., crossed, straight), and head (e.g., tilted, looking forward)]. [Describe the subject's action or gesture (e.g., holding a cup, pointing, walking, reading) and overall body language. Describe the facial expression type (e.g., a wide smile, a serious expression, a thoughtful look, a laugh) but NOT the features.]

The scene: [Describe the location type (e.g., a city street, a living room, a forest, an office)]. The environment features [describe all significant background and foreground elements: architectural details (e.g., buildings, windows, walls), furniture (e.g., chairs, tables, lamps), props (e.g., books, plants, cars), and natural elements (e.g., trees, mountains, water)]. The setting is [describe the spatial layout, e.g., "indoors in a cluttered studio," "outdoors on a crowded beach"].

Lighting: [Describe the lighting in technical detail: identify the primary light source(s) (e.g., sun, studio softbox, window, lamp), its direction (e.g., side-lit, backlit, overhead, three-point lighting), its quality (e.g., hard, soft, diffused), and the resulting shadows (e.g., long and soft, sharp and deep). Note the time of day (e.g., golden hour, midday, night) and the overall color temperature (e.g., warm, cool, neutral).]

Camera: [Describe the camera's properties: the angle (e.g., eye-level, low-angle, high-angle, dutch angle), the shot type (e.g., full-body shot, medium shot, cowboy shot), the depth of field (e.g., shallow with heavy bokeh, deep with everything in focus), and the overall composition (e.g., rule of thirds, centered, leading lines).]

Atmosphere: [Describe the mood or ambiance of the scene (e.g., serene, chaotic, melancholic, energetic, professional, mysterious). If outdoors, note weather conditions (e.g., sunny, overcast, rainy, foggy) or environmental effects (e.g., lens flare, mist).]

Colors and textures: [Describe the dominant color palette of the entire image (e.g., monochrome with a blue tint, vibrant analogous colors, muted complementary colors). Highlight key materials and their surface textures (e.g., smooth glass, rough brick, shiny metal, matte fabric, glossy paint).]

Technical quality: [Describe the image's aesthetic and technical style, e.g., high-resolution, photorealistic, sharp focus, professional studio photography, cinematic, 35mm film grain, editorial fashion shot, candid.]

CRITICAL RULES (ABSOLUTE):
DO use generic terms: "this person," "the subject," "the individual."
DO be extremely detailed about clothing, accessories, pose, and background elements. These are your primary focus.
DO describe the type of facial expression (e.g., smiling, frowning, pensive) as this is part of the "pose" and "action."
NEVER describe: hair color, hair style, eye color, facial features, skin tone, ethnic features
Be extremely detailed about clothing and accessories
Be precise about pose and body position
Focus on EVERYTHING visible except facial/hair features
Output ONLY the formatted prompt, nothing else."""
    
    def _generate_with_gemini(self, prompt_text: str, ref_images: List[bytes], sample_image: bytes) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞ —á–µ—Ä–µ–∑ Gemini"""
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        parts = [prompt_text]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–µ—Ä–≤—ã–µ 2)
        for img_data in ref_images[:2]:
            parts.append({
                'mime_type': 'image/jpeg',
                'data': img_data
            })
        
        # –î–æ–±–∞–≤–ª—è–µ–º sample –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Ç—Ä–µ—Ç—å–µ)
        parts.append({
            'mime_type': 'image/jpeg',
            'data': sample_image
        })
        
        response = self.client.generate_content(parts)
        return response.text.strip()
    
    def _generate_with_openai(self, prompt_text: str, ref_images: List[bytes], sample_image: bytes) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞ —á–µ—Ä–µ–∑ OpenAI"""
        import base64
        
        messages = [{
            "role": "user",
            "content": [
                {"type": "text", "text": prompt_text}
            ]
        }]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for img_data in ref_images[:2]:
            img_b64 = base64.b64encode(img_data).decode('utf-8')
            messages[0]["content"].append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{img_b64}"
                }
            })
        
        # –î–æ–±–∞–≤–ª—è–µ–º sample –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        sample_b64 = base64.b64encode(sample_image).decode('utf-8')
        messages[0]["content"].append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{sample_b64}"
            }
        })
        
        # –î–ª—è GPT-5 –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è max_completion_tokens –≤–º–µ—Å—Ç–æ max_tokens
        model = self.config.openai_model
        response_params = {
            'model': model,
            'messages': messages
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∞—è –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
        if 'gpt-5' in model.lower() or 'gpt-4o' in model.lower():
            response_params['max_completion_tokens'] = 35000
        else:
            # –î–ª—è —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º max_tokens
            response_params['max_tokens'] = 35000
        
        response = self.client.chat.completions.create(**response_params)
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π
        if response.choices and len(response.choices) > 0:
            choice = response.choices[0]
            message = choice.message
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º finish_reason
            finish_reason = getattr(choice, 'finish_reason', None)
            if finish_reason == 'length':
                print(f"   ‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –û—Ç–≤–µ—Ç –±—ã–ª –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ (finish_reason: length)")
                if hasattr(response, 'usage') and response.usage:
                    print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ completion tokens: {response.usage.completion_tokens}")
                    print(f"   –õ–∏–º–∏—Ç: {response_params.get('max_completion_tokens', response_params.get('max_tokens', 'N/A'))}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
            message_content = getattr(message, 'content', None)
            
            if message_content:
                prompt = message_content.strip()
                if prompt:
                    return prompt
                else:
                    print(f"   ‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞. –ú–æ–¥–µ–ª—å: {model}")
                    print(f"   Finish reason: {finish_reason}")
                    return ""
            else:
                print(f"   ‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: OpenAI –≤–µ—Ä–Ω—É–ª None –¥–ª—è message.content. –ú–æ–¥–µ–ª—å: {model}")
                print(f"   Finish reason: {finish_reason}")
                print(f"   Message type: {type(message)}")
                print(f"   Message attributes: {[attr for attr in dir(message) if not attr.startswith('_')]}")
                return ""
        else:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞: OpenAI –Ω–µ –≤–µ—Ä–Ω—É–ª choices –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞. –ú–æ–¥–µ–ª—å: {model}")
            return ""


class ImageGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Wavespeed"""
    
    def __init__(self, config: Config):
        self.config = config
        self.setup_provider()
    
    def setup_provider(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        if self.config.image_provider == 'wavespeed':
            if not self.config.wavespeed_api_key:
                raise ValueError("Wavespeed API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {self.config.image_provider}")
    
    def generate_image(self, ref_images: List[bytes], sample_image: bytes, prompt: str, output_path: str):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/–≤–∏–¥–µ–æ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ"""
        if self.config.image_provider == 'wavespeed':
            self._generate_with_wavespeed(ref_images, sample_image, prompt, output_path)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.config.image_provider}")
    
    def _generate_with_wavespeed(self, ref_images: List[bytes], sample_image: bytes, prompt: str, output_path: str):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Wavespeed API —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        model = self.config.wavespeed_model
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –∏ endpoint
        if 'image-to-video' in model or '/video' in model:
            self._generate_video_wavespeed(ref_images, sample_image, prompt, output_path, model)
        else:
            # –í—Å–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç image-to-image (edit, seedream)
            self._generate_image_edit_wavespeed(ref_images, sample_image, prompt, output_path, model)
    
    def _generate_image_edit_wavespeed(self, ref_images: List[bytes], sample_image: bytes, prompt: str, output_path: str, model: str):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Wavespeed Image-to-Image API (edit –º–æ–¥–µ–ª–∏)"""
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –º–æ–¥–µ–ª–∏ (–∑–∞–º–µ–Ω—è–µ–º / –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
        model_path = model
        url = f"https://api.wavespeed.ai/api/v3/{model_path}"
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ base64
        images_base64 = []
        for img_data in ref_images[:2]:
            images_base64.append(base64.b64encode(img_data).decode('utf-8'))
        images_base64.append(base64.b64encode(sample_image).decode('utf-8'))
        
        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –æ—Ç –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫
        clean_prompt = prompt.replace('\n', ' ').replace('\r', ' ')
        
        payload = {
            "enable_base64_output": False,
            "enable_sync_mode": True,  # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å—Ä–∞–∑—É
            "images": images_base64,
            "prompt": clean_prompt
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if hasattr(self.config, 'wavespeed_resolution') and self.config.wavespeed_resolution:
            payload["resolution"] = self.config.wavespeed_resolution
        if hasattr(self.config, 'wavespeed_output_format') and self.config.wavespeed_output_format:
            payload["output_format"] = self.config.wavespeed_output_format
        if hasattr(self.config, 'wavespeed_size') and self.config.wavespeed_size and 'size' not in payload:
            # –î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è size –≤–º–µ—Å—Ç–æ resolution
            if '*' in self.config.wavespeed_size:
                width, height = self.config.wavespeed_size.split('*')
                payload["width"] = int(width)
                payload["height"] = int(height)
            else:
                payload["size"] = self.config.wavespeed_size
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.config.wavespeed_api_key}"
        }
        
        response = self._make_wavespeed_request(url, payload, headers, output_path, is_video=False)
        return response
    
    def _generate_video_wavespeed(self, ref_images: List[bytes], sample_image: bytes, prompt: str, output_path: str, model: str):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Wavespeed Image-to-Video API"""
        model_path = model
        url = f"https://api.wavespeed.ai/api/v3/{model_path}"
        
        # –î–ª—è video –∏—Å–ø–æ–ª—å–∑—É–µ–º sample_image –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_base64 = base64.b64encode(sample_image).decode('utf-8')
        
        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–∞
        clean_prompt = prompt.replace('\n', ' ').replace('\r', ' ')
        
        payload = {
            "enable_base64_output": False,
            "enable_sync_mode": False,  # –í–∏–¥–µ–æ –æ–±—ã—á–Ω–æ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ
            "image": image_base64,
            "prompt": clean_prompt
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.config.wavespeed_api_key}"
        }
        
        response = self._make_wavespeed_request(url, payload, headers, output_path, is_video=True)
        return response
    
    def _make_wavespeed_request(self, url: str, payload: Dict, headers: Dict, output_path: str, is_video: bool = False):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Wavespeed API —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        i18n = get_i18n()
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ retry —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=2,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 1 –¥–æ 2 –¥–ª—è –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–¥–µ—Ä–∂–µ–∫
            status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è image-to-image (–º–æ–∂–µ—Ç –∑–∞–Ω–∏–º–∞—Ç—å –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏)
        timeout_seconds = 900 if is_video else 600  # 15 –º–∏–Ω—É—Ç –¥–ª—è –≤–∏–¥–µ–æ, 10 –º–∏–Ω—É—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        try:
            response = session.post(url, json=payload, headers=headers, timeout=timeout_seconds)
            response.raise_for_status()
            result = response.json()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞ Wavespeed —Å –æ–±–µ—Ä—Ç–∫–æ–π {code, message, data}
            if 'data' in result:
                data = result['data']
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
                if data.get('status') == 'failed' or data.get('error'):
                    i18n = get_i18n()
                    error_msg = data.get('error', i18n.t('unknown_error'))
                    raise RuntimeError(i18n.t('wavespeed_api_error', error=error_msg))
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ data
                result = data
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if is_video:
                # –î–ª—è –≤–∏–¥–µ–æ
                video_url = None
                if 'video' in result:
                    video_url = result.get('video')
                elif 'video_url' in result:
                    video_url = result.get('video_url')
                elif 'outputs' in result and isinstance(result['outputs'], list) and len(result['outputs']) > 0:
                    # Wavespeed –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ URL –≤ outputs
                    video_url = result['outputs'][0]
                
                if video_url:
                    video_response = requests.get(video_url, timeout=300)
                    video_response.raise_for_status()
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–∑ URL –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º mp4
                    ext = 'mp4'
                    if '.' in video_url:
                        ext = video_url.split('.')[-1].split('?')[0]
                    output_path = output_path.replace('.png', f'.{ext}').replace('.jpg', f'.{ext}')
                    with open(output_path, 'wb') as f:
                        f.write(video_response.content)
                elif 'video_base64' in result:
                    video_data = base64.b64decode(result['video_base64'])
                    output_path = output_path.replace('.png', '.mp4').replace('.jpg', '.mp4')
                    with open(output_path, 'wb') as f:
                        f.write(video_data)
                else:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    with open(output_path.replace('.png', '_response.json').replace('.mp4', '_response.json'), 'w') as f:
                        json.dump(result, f, indent=2)
                    raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –≤–∏–¥–µ–æ: {result.keys()}")
            else:
                # –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                image_url = None
                if 'image' in result:
                    image_url = result.get('image')
                elif 'image_url' in result:
                    image_url = result.get('image_url')
                elif 'outputs' in result and isinstance(result['outputs'], list) and len(result['outputs']) > 0:
                    # Wavespeed –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ URL –≤ outputs
                    image_url = result['outputs'][0]
                
                if image_url:
                    img_response = requests.get(image_url, timeout=300)
                    img_response.raise_for_status()
                    with open(output_path, 'wb') as f:
                        f.write(img_response.content)
                elif 'image_base64' in result:
                    img_data = base64.b64decode(result['image_base64'])
                    with open(output_path, 'wb') as f:
                        f.write(img_data)
                else:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    with open(output_path.replace('.png', '_response.json').replace('.jpg', '_response.json'), 'w') as f:
                        json.dump(result, f, indent=2)
                    raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {result.keys()}")
            
            return result
            
        except requests.exceptions.Timeout as e:
            i18n = get_i18n()
            error_msg = i18n.t('wavespeed_timeout_error', timeout=timeout_seconds)
            if hasattr(e, 'response') and e.response is not None and hasattr(e.response, 'text'):
                error_msg += f"\n{i18n.t('server_response')}: {e.response.text[:200]}"
            raise RuntimeError(error_msg)
        except requests.exceptions.RequestException as e:
            i18n = get_i18n()
            error_msg = i18n.t('wavespeed_request_error', error=str(e))
            if hasattr(e, 'response') and e.response is not None:
                if hasattr(e.response, 'status_code'):
                    error_msg += f" (HTTP {e.response.status_code})"
                if hasattr(e.response, 'text'):
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞
                    server_response = e.response.text[:500]
                    error_msg += f"\n{i18n.t('server_response')}: {server_response}"
            raise RuntimeError(error_msg)


class CaptionGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ–¥–ø–∏—Å–µ–π (captions) –¥–ª—è LoRA –æ–±—É—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ OpenAI"""
    
    def __init__(self, config: Config):
        self.config = config
        if not OPENAI_AVAILABLE:
            raise ImportError("openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
        if not config.openai_api_key:
            raise ValueError("OpenAI API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        self.client = OpenAI(api_key=config.openai_api_key)
    
    def generate_caption(self, image_path: str, trigger_name: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥–ø–∏—Å—å –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        import base64
        
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        with open(image_path, 'rb') as f:
            image_data = f.read()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
        image_b64 = base64.b64encode(image_data).decode('utf-8')
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–∏
        prompt_text = f"""These are photos of {trigger_name}, analyze those images and caption them correctly for a LoRA training using "{trigger_name}" as the caption token. 

Be detailed and describe all aspects of the character visible in the image:
- Clothing and accessories (every detail)
- Pose and body position
- Action and gesture
- Scene and environment
- Lighting and atmosphere
- Colors and textures

Important: Use "{trigger_name}" as the main token. Be specific about features (e.g., "{trigger_name} with blonde hair" instead of just "{trigger_name}") so those traits become part of the character's identity.

Output ONLY the caption text, nothing else. Do not include file names or any other text."""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è captions, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞, –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å
        caption_model = getattr(self.config, 'openai_caption_model', None) or self.config.openai_model
        
        # –î–ª—è GPT-5 –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è max_completion_tokens –≤–º–µ—Å—Ç–æ max_tokens
        response_params = {
            'model': caption_model,
            'messages': [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt_text},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_b64}"
                            }
                        }
                    ]
                }
            ]
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∞—è –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
        if 'gpt-5' in caption_model.lower() or 'gpt-4o' in caption_model.lower():
            response_params['max_completion_tokens'] = 500
        else:
            # –î–ª—è —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º max_tokens
            response_params['max_tokens'] = 500
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
        response = self.client.chat.completions.create(**response_params)
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ caption
        if response.choices and len(response.choices) > 0:
            message_content = response.choices[0].message.content
            if message_content:
                caption = message_content.strip()
            else:
                caption = ""
                print(f"   ‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –ú–æ–¥–µ–ª—å {caption_model} –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç. –í–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (vision).")
        else:
            caption = ""
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å {caption_model} –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Ç–≤–µ—Ç.")
        
        return caption


class DatasetCreator:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    
    def __init__(self, config: Config):
        self.config = config
        self.file_manager = LocalFileManager()
        self.prompt_generator = PromptGenerator(config)
        self.image_generator = ImageGenerator(config)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ–¥–ø–∏—Å–µ–π —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        self.caption_generator = None
        if self.config.generate_captions and self.config.trigger_name:
            try:
                self.caption_generator = CaptionGenerator(config)
            except Exception as e:
                i18n = get_i18n()
                print(f"   ‚ö†Ô∏è  {i18n.t('caption_generation_skipped_error', error=e)}")
                print(f"   {i18n.t('caption_generation_skipped')}")
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É
        Path(self.config.output_folder).mkdir(parents=True, exist_ok=True)
        
        # –°–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è captions
        self.generated_images = []
    
    def _get_unique_file_path(self, base_path: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞, –¥–æ–±–∞–≤–ª—è—è timestamp –µ—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        path = Path(base_path)
        output_dir = path.parent
        stem = path.stem
        suffix = path.suffix
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å
        if not path.exists():
            return str(path)
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_path = output_dir / f"{stem}_{timestamp}{suffix}"
        
        # –ï—Å–ª–∏ –∏ —Å timestamp —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π), –¥–æ–±–∞–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫
        counter = 1
        while unique_path.exists():
            unique_path = output_dir / f"{stem}_{timestamp}_{counter}{suffix}"
            counter += 1
        
        return str(unique_path)
    
    def process_dataset(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç"""
        i18n = get_i18n()
        print(f"üìÅ {i18n.t('loading_ref_images')}")
        ref_files = self.file_manager.list_image_files(
            self.config.influencer_ref_folder,
            self.config.limit_ref_images
        )
        print(f"   {i18n.t('found_ref_images', count=len(ref_files))}")
        
        print(f"üìÅ {i18n.t('loading_sample_images')}")
        # –õ–æ–≥–∏–∫–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º Make.com workflow):
        # - bulk: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç listAllFilesSubfoldersInFolder —Å limit=10 ‚Üí –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ú–ù–û–ì–û –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        # - detailed: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç getFile —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º —Ñ–∞–π–ª–æ–º ‚Üí –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –û–î–ù–û –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if self.config.prompt_template == 'detailed':
            # –î–ª—è detailed –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞
            limit = self.config.limit_sample_images
            print(f"   {i18n.t('mode_detailed')}")
            print(f"   {i18n.t('mode_detailed_corresponds')}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞
            all_sample_files = self.file_manager.list_image_files(
                self.config.sample_dataset_folder,
                limit
            )
            print(f"   {i18n.t('found_sample_images', count=len(all_sample_files))}")
            
            # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            selected_file = self._select_sample_image(all_sample_files)
            if not selected_file:
                print(f"   ‚ö†Ô∏è  {i18n.t('image_not_selected')}")
                return
            
            sample_files = [selected_file]
            print(f"   ‚úì {i18n.t('image_selected', name=selected_file['name'])}")
        else:
            # –î–ª—è bulk –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ –ª–∏–º–∏—Ç–∞ (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º workflow)
            limit = self.config.limit_sample_images
            print(f"   {i18n.t('mode_bulk', limit=limit)}")
            print(f"   {i18n.t('mode_bulk_corresponds', limit=limit)}")
            
            sample_files = self.file_manager.list_image_files(
                self.config.sample_dataset_folder,
                limit
            )
            print(f"   {i18n.t('found_sample_images_for_processing', count=len(sample_files))}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        ref_images_data = []
        for ref_file in ref_files[:2]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2
            data, _ = self.file_manager.read_file(ref_file['path'])
            ref_images_data.append(data)
            print(f"   ‚úì {ref_file['name']}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ sample –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        for idx, sample_file in enumerate(sample_files, 1):
            print(f"\nüñºÔ∏è  {i18n.t('processing_image', current=idx, total=len(sample_files), name=sample_file['name'])}")
            
            try:
                # –ß–∏—Ç–∞–µ–º sample –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                sample_data, sample_name = self.file_manager.read_file(sample_file['path'])
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
                print(f"   ü§ñ {i18n.t('generating_prompt')}")
                prompt = self.prompt_generator.generate_prompt(ref_images_data, sample_data)
                print(f"   ‚úì {i18n.t('prompt_generated', length=len(prompt))}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç (—Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º)
                base_prompt_path = os.path.join(
                    self.config.output_folder,
                    f"{Path(sample_name).stem}_prompt.txt"
                )
                prompt_path = self._get_unique_file_path(base_prompt_path)
                with open(prompt_path, 'w', encoding='utf-8') as f:
                    f.write(prompt)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –≤—ã–≤–æ–¥–∞ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –≤–∏–¥–µ–æ)
                is_video = False
                if self.config.image_provider == 'wavespeed':
                    is_video = ('image-to-video' in self.config.wavespeed_model or 
                               '/video' in self.config.wavespeed_model or
                               'video' in self.config.wavespeed_model.lower())
                output_type = "–≤–∏–¥–µ–æ" if is_video else "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
                default_ext = "mp4" if is_video else "png"
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/–≤–∏–¥–µ–æ
                model_name = self.config.wavespeed_model
                print(f"   üé® {i18n.t('generating_image', provider=self.config.image_provider, model=model_name)}")
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                if self.config.generate_captions and self.config.trigger_name and not is_video:
                    # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è captions, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç trigger_name_0001.png
                    img_index = len(self.generated_images) + 1
                    lora_dir = Path(self.config.output_folder) / "lora_dataset"
                    lora_dir.mkdir(exist_ok=True)
                    output_path = lora_dir / f"{self.config.trigger_name}_{img_index:04d}.{default_ext}"
                else:
                    # –û–±—ã—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
                    base_output_path = os.path.join(
                        self.config.output_folder,
                        f"{Path(sample_name).stem}_generated.{default_ext}"
                    )
                    output_path = self._get_unique_file_path(base_output_path)
                
                self.image_generator.generate_image(
                    ref_images_data,
                    sample_data,
                    prompt,
                    str(output_path)
                )
                if is_video:
                    print(f"   ‚úì {i18n.t('video_saved', path=output_path)}")
                else:
                    print(f"   ‚úì {i18n.t('image_saved', path=output_path)}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è captions
                if not is_video:  # Captions —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –Ω–µ –¥–ª—è –≤–∏–¥–µ–æ
                    self.generated_images.append({
                        'path': str(output_path),
                        'original_name': sample_name,
                        'index': len(self.generated_images) + 1  # –ò–Ω–¥–µ–∫—Å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 1 –¥–ª—è _0001, _0002 –∏ —Ç.–¥.
                    })
                
            except Exception as e:
                i18n = get_i18n()
                print(f"   ‚ùå {i18n.t('error_processing_image')}: {sample_file['name']}: {e}")
                continue
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º captions –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.config.generate_captions and self.config.trigger_name and self.generated_images:
            print(f"\nüìù {i18n.t('generating_captions')}")
            self._generate_captions()
        
        print(f"\n‚úÖ {i18n.t('processing_completed', path=self.config.output_folder)}")
    
    def _select_sample_image(self, sample_files: List[Dict]) -> Optional[Dict]:
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ Sample Dataset"""
        if not sample_files:
            print("   ‚ö†Ô∏è  –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –≤—ã–±–æ—Ä–∞")
            return None
        
        print("\n" + "="*60)
        print("  üñºÔ∏è  –í—ã–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ Sample Dataset")
        print("="*60)
        print("\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")
        
        for idx, file_info in enumerate(sample_files, 1):
            size_mb = file_info.get('size', 0) / (1024 * 1024)
            print(f"   [{idx}] {file_info['name']} ({size_mb:.2f} MB)")
        
        print(f"\n   [0] –û—Ç–º–µ–Ω–∞")
        
        while True:
            try:
                choice = input("\n   –í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (1-{} –∏–ª–∏ 0 –¥–ª—è –æ—Ç–º–µ–Ω—ã): ".format(len(sample_files))).strip()
                
                if choice == '0':
                    return None
                
                choice_num = int(choice)
                if 1 <= choice_num <= len(sample_files):
                    return sample_files[choice_num - 1]
                else:
                    print(f"   ‚ö†Ô∏è  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ {len(sample_files)} –∏–ª–∏ 0 –¥–ª—è –æ—Ç–º–µ–Ω—ã")
            except ValueError:
                print(f"   ‚ö†Ô∏è  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ {len(sample_files)} –∏–ª–∏ 0 –¥–ª—è –æ—Ç–º–µ–Ω—ã")
            except KeyboardInterrupt:
                print("\n   ‚ö†Ô∏è  –í—ã–±–æ—Ä –æ—Ç–º–µ–Ω–µ–Ω")
                return None
    
    def _generate_captions(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥–ø–∏—Å–∏ –¥–ª—è –≤—Å–µ—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Å–æ–∑–¥–∞–µ—Ç zip –∞—Ä—Ö–∏–≤"""
        i18n = get_i18n()
        if not self.caption_generator:
            print(f"   ‚ö†Ô∏è  {i18n.t('caption_generator_not_initialized')}")
            return
        
        trigger_name = self.config.trigger_name
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ø–∞–ø–∫—É, –≥–¥–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (lora_dataset)
        lora_dir = Path(self.config.output_folder) / "lora_dataset"
        lora_dir.mkdir(exist_ok=True)
        
        caption_files = []
        image_files = []
        
        for img_info in self.generated_images:
            img_path = Path(img_info['path'])
            img_index = img_info['index']
            
            try:
                print(f"   üìù {i18n.t('generating_caption_for', name=img_path.name)}")
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–¥–ø–∏—Å—å
                caption = self.caption_generator.generate_caption(str(img_path), trigger_name)
                
                # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞: trigger_name_0001.txt, trigger_name_0002.txt –∏ —Ç.–¥.
                caption_filename = f"{trigger_name}_{img_index:04d}.txt"
                caption_path = lora_dir / caption_filename
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–¥–ø–∏—Å—å –≤ —Ç—É –∂–µ –ø–∞–ø–∫—É, –≥–¥–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                with open(caption_path, 'w', encoding='utf-8') as f:
                    f.write(caption)
                
                caption_files.append({
                    'path': caption_path,
                    'filename': caption_filename
                })
                
                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ lora_dir —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–º—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É trigger_name_XXXX.png
                expected_img_name = f"{trigger_name}_{img_index:04d}{img_path.suffix}"
                if img_path.parent != lora_dir or img_path.name != expected_img_name:
                    # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –≤ lora_dir –∏–ª–∏ —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º, –∫–æ–ø–∏—Ä—É–µ–º/–ø–µ—Ä–µ–º–µ—â–∞–µ–º –µ–≥–æ
                    new_img_path = lora_dir / expected_img_name
                    if img_path.exists():
                        shutil.copy2(img_path, new_img_path)
                        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –æ–Ω–æ –±—ã–ª–æ –≤ –¥—Ä—É–≥–æ–π –ø–∞–ø–∫–µ
                        if img_path.parent != lora_dir:
                            try:
                                img_path.unlink()
                            except:
                                pass
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
                    img_info['path'] = str(new_img_path)
                    image_files.append({
                        'path': new_img_path,
                        'filename': expected_img_name
                    })
                else:
                    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–∞–ø–∫–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
                    image_files.append({
                        'path': img_path,
                        'filename': img_path.name
                    })
                
                print(f"   ‚úì –ü–æ–¥–ø–∏—Å—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {caption_filename}")
                
            except Exception as e:
                print(f"   ‚ùå {i18n.t('error_generating_caption_for', name=img_path.name, error=e)}")
                continue
        
        # –°–æ–∑–¥–∞–µ–º zip –∞—Ä—Ö–∏–≤ —Å–æ –≤—Å–µ–º–∏ —Ñ–∞–π–ª–∞–º–∏ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + –ø–æ–¥–ø–∏—Å–∏)
        if caption_files:
            zip_path = Path(self.config.output_folder) / f"{trigger_name}_lora_dataset.zip"
            i18n = get_i18n()
            print(f"\n   üì¶ {i18n.t('creating_zip', name=zip_path.name)}")
            
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                for img_file in image_files:
                    zipf.write(img_file['path'], img_file['filename'])
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏
                for caption_file in caption_files:
                    zipf.write(caption_file['path'], caption_file['filename'])
            
            print(f"   ‚úì {i18n.t('zip_created_path', path=zip_path)}")
            print(f"   üìÅ {i18n.t('total_files', images=len(image_files), captions=len(caption_files))}")
            print(f"   üìÇ {i18n.t('all_files_saved_in', path=lora_dir)}")


def select_or_create_profile() -> Optional[str]:
    """–í—ã–±–æ—Ä —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ"""
    i18n = get_i18n()
    config = Config()
    profiles = config.list_profiles()
    
    print("\n" + "="*60)
    print(f"  üìã {i18n.t('profile_management')}")
    print("="*60)
    
    if profiles:
        print(f"\n{i18n.t('found_profiles', count=len(profiles))}\n")
        for idx, profile in enumerate(profiles, 1):
            desc = f" - {profile['description']}" if profile.get('description') else ""
            print(f"   [{idx}] {profile['name']}{desc}")
        print(f"   [0] {i18n.t('create_new_profile')}")
        print(f"   [Enter] {i18n.t('skip_use_temporary')}")
        
        choice = input(f"\n{i18n.t('your_choice')}: ").strip()
        
        if choice == '0' or choice.lower() == 'new':
            return None  # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π
        elif choice == '':
            return None  # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å
        elif choice.isdigit() and 1 <= int(choice) <= len(profiles):
            selected = profiles[int(choice) - 1]
            print(f"\n‚úì {i18n.t('selected_profile', name=selected['name'])}")
            return selected['file']
        else:
            print(f"‚ö† {i18n.t('invalid_choice_create_new')}")
            return None
    else:
        print(f"\n{i18n.t('no_profiles_saved')}")
        print(f"   [1] {i18n.t('create_new_profile')}")
        print(f"   [Enter] {i18n.t('skip_use_temporary')}")
        
        choice = input(f"\n{i18n.t('your_choice')}: ").strip()
        if choice == '1':
            return None  # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π
        else:
            return None  # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å


def save_profile_menu(config: Config):
    """–ú–µ–Ω—é —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è"""
    i18n = get_i18n()
    print("\n" + "="*60)
    print(f"  üíæ {i18n.t('save_profile_title')}")
    print("="*60)
    print(f"\n{i18n.t('want_to_save_profile')}")
    print(f"   [1] {i18n.t('yes_save')}")
    print(f"   [2] {i18n.t('no_skip')}")
    
    i18n = get_i18n()
    choice = input(f"\n{i18n.t('your_choice')} (1/2): ").strip()
    
    if choice == '1':
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏–º—è –ø—Ä–æ—Ñ–∏–ª—è
        print(f"\n{i18n.t('enter')} {i18n.t('profile_name').lower()} (–ª–∞—Ç–∏–Ω–∏—Ü–∞, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤):")
        print("   –ü—Ä–∏–º–µ—Ä—ã: 'production', 'test', 'video-generation'")
        profile_name = input(f"{i18n.t('profile_name')}: ").strip()
        
        if not profile_name:
            i18n = get_i18n()
            print(f"‚ö† {i18n.t('profile_name')} –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")
            return
        
        # –û—á–∏—â–∞–µ–º –∏–º—è –æ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        import re
        profile_name = re.sub(r'[^a-zA-Z0-9_-]', '_', profile_name)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–æ—Ñ–∏–ª—å
        existing_profiles = config.list_profiles()
        profile_exists = any(p['file'] == profile_name for p in existing_profiles)
        
        if profile_exists:
            i18n = get_i18n()
            print(f"\n‚ö† {i18n.t('profile_already_exists', name=profile_name)}")
            print(f"   [1] {i18n.t('overwrite_existing')}")
            print(f"   [2] {i18n.t('cancel_saving')}")
            overwrite = input(f"   {i18n.t('your_choice')} (1/2): ").strip()
            if overwrite != '1':
                print(f"   ‚Üí {i18n.t('saving_cancelled')}")
                return
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        i18n = get_i18n()
        print(f"\n{i18n.t('enter_profile_description')}")
        print(f"   {i18n.t('profile_description_example', example='–î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–µ—Ä–æ–≤ —Å Seedream 4.5')}")
        description = input(f"{i18n.t('enter')}: ").strip()
        
        try:
            profile_path = config.save_to_profile(profile_name, description)
            i18n = get_i18n()
            if profile_exists:
                print(f"\n‚úÖ {i18n.t('profile_updated', name=profile_name)}")
            else:
                print(f"\n‚úÖ {i18n.t('profile_created', name=profile_name)}")
            print(f"   {i18n.t('profile_path', path=profile_path)}")
        except Exception as e:
            i18n = get_i18n()
            print(f"\n‚ùå {i18n.t('error_saving_profile', error=e)}")
            import traceback
            traceback.print_exc()
    else:
        i18n = get_i18n()
        print(f"\n‚Üí {i18n.t('settings_not_saved')}")


def interactive_menu(config: Config) -> Config:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –º–µ–Ω—é –¥–ª—è –≤—ã–±–æ—Ä–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    i18n = get_i18n()
    print("\n" + "="*60)
    print(f"  üé® {i18n.t('interactive_menu_title')}")
    print("="*60)
    print(f"\n{i18n.t('select_settings')}\n")
    
    # –í—ã–±–æ—Ä AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    print(f"1Ô∏è‚É£  {i18n.t('ai_provider')}:")
    current_ai = config.ai_provider if config.ai_provider else i18n.t('not_selected')
    print(f"   {i18n.t('current_value')}: {current_ai}")
    print(f"\n   [1] Gemini (Google Gemini 2.5 Flash)")
    print(f"       ‚úì {i18n.t('gemini_description_1')}")
    print(f"       ‚úì {i18n.t('gemini_description_2')}")
    print(f"       ‚úì {i18n.t('gemini_description_3')}")
    print(f"       ‚úì {i18n.t('gemini_description_4')}")
    print(f"       ‚ö†Ô∏è  {i18n.t('gemini_description_5')}")
    print(f"       üí° {i18n.t('gemini_description_6')}")
    print(f"\n   [2] OpenAI (GPT-5 mini)")
    print(f"       ‚úì {i18n.t('openai_description_1')}")
    print(f"       ‚úì {i18n.t('openai_description_2')}")
    print(f"       ‚úì {i18n.t('openai_description_3')}")
    print(f"       ‚úì {i18n.t('openai_description_4')}")
    print(f"       ‚úì {i18n.t('openai_description_5')}")
    print(f"       ‚ö†Ô∏è  {i18n.t('openai_description_6')}")
    print(f"       üí° {i18n.t('openai_description_7')}")
    choice = input(f"\n   {i18n.t('your_choice')} (1/2 {i18n.t('or')} {i18n.t('press_enter_to_skip')}): ").strip()
    if choice == '1':
        config.ai_provider = 'gemini'
        print(f"   ‚úì {i18n.t('selected')}: Gemini")
    elif choice == '2':
        config.ai_provider = 'openai'
        print(f"   ‚úì {i18n.t('selected')}: OpenAI")
    else:
        if config.ai_provider:
            print(f"   ‚Üí {i18n.t('using_value')}: {config.ai_provider}")
        else:
            print(f"   ‚ö†Ô∏è  {i18n.t('ai_provider')} {i18n.t('not_selected')}! {i18n.t('select_option')}.")
            # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å –µ—Å–ª–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω
            while not config.ai_provider:
                choice = input(f"   {i18n.t('your_choice')} (1/2, {i18n.t('must_select')}): ").strip()
                if choice == '1':
                    config.ai_provider = 'gemini'
                    print(f"   ‚úì {i18n.t('selected')}: Gemini")
                elif choice == '2':
                    config.ai_provider = 'openai'
                    print(f"   ‚úì {i18n.t('selected')}: OpenAI")
                else:
                    print(f"   ‚ö†Ô∏è  {i18n.t('please_select_1_or_2')}")
    
    # –í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞
    print(f"\n2Ô∏è‚É£  {i18n.t('processing_mode')}:")
    current_template = config.prompt_template if hasattr(config, 'prompt_template') and config.prompt_template else "bulk"
    print(f"   {i18n.t('current_value')}: {current_template}")
    print(f"\n   ‚ö†Ô∏è  {i18n.t('prompt_same_note')}")
    print(f"   {i18n.t('prompt_difference_note')}\n")
    print(f"   [1] {i18n.t('bulk_mode_title')}")
    print(f"       üìä {i18n.t('bulk_mode_1')}")
    print(f"       üìã {i18n.t('bulk_mode_2')}")
    print(f"       üìù {i18n.t('bulk_mode_3')}")
    print(f"       ‚úì {i18n.t('bulk_mode_4')}")
    print(f"       ‚úì {i18n.t('bulk_mode_5')}")
    print(f"       üí° {i18n.t('bulk_mode_6')}")
    print(f"\n   [2] {i18n.t('detailed_mode_title')}")
    print(f"       üìä {i18n.t('detailed_mode_1')}")
    print(f"       üìã {i18n.t('detailed_mode_2')}")
    print(f"       üìù {i18n.t('detailed_mode_3')}")
    print(f"       ‚úì {i18n.t('detailed_mode_4')}")
    print(f"       ‚úì {i18n.t('detailed_mode_5')}")
    print(f"       üí° {i18n.t('detailed_mode_6')}")
    choice = input(f"\n   {i18n.t('your_choice')} (1/2 {i18n.t('or')} {i18n.t('press_enter_to_skip')}): ").strip()
    if choice == '1':
        config.prompt_template = 'bulk'
        print(f"   ‚úì {i18n.t('selected')}: bulk")
    elif choice == '2':
        config.prompt_template = 'detailed'
        print(f"   ‚úì {i18n.t('selected')}: detailed")
    else:
        print(f"   ‚Üí {i18n.t('using_value')} –∏–∑ config: {config.prompt_template}")
    
    # –í—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    print(f"\n3Ô∏è‚É£  {i18n.t('image_generation_provider')}:")
    current_provider = config.image_provider if config.image_provider else i18n.t('not_selected')
    print(f"   {i18n.t('current_value')}: {current_provider}")
    print(f"\n   [1] Wavespeed")
    print(f"       ‚úì {i18n.t('wavespeed_description_1')}")
    print(f"       ‚úì {i18n.t('wavespeed_description_2')}")
    print(f"       ‚úì {i18n.t('wavespeed_description_3')}")
    print(f"       ‚úì {i18n.t('wavespeed_description_4')}")
    print(f"       ‚úì {i18n.t('wavespeed_description_5')}")
    print(f"       üí° {i18n.t('wavespeed_description_6')}")
    choice = input(f"\n   {i18n.t('your_choice')} (1 {i18n.t('or')} {i18n.t('press_enter_to_skip')}): ").strip()
    if choice == '1':
        config.image_provider = 'wavespeed'
        print(f"   ‚úì {i18n.t('selected')}: Wavespeed")
    else:
        if config.image_provider:
            print(f"   ‚Üí {i18n.t('using_value')}: {config.image_provider}")
        else:
            print(f"   ‚ö†Ô∏è  {i18n.t('image_generation_provider')} {i18n.t('not_selected')}! {i18n.t('select_option')}.")
            # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å –µ—Å–ª–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω
            while not config.image_provider:
                choice = input(f"   {i18n.t('your_choice')} (1, {i18n.t('must_select')}): ").strip()
                if choice == '1':
                    config.image_provider = 'wavespeed'
                    print(f"   ‚úì {i18n.t('selected')}: Wavespeed")
                else:
                    print(f"   ‚ö†Ô∏è  {i18n.t('please_select_1')}")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ Wavespeed
    if config.image_provider == 'wavespeed':
        print(f"\n4Ô∏è‚É£  {i18n.t('wavespeed_model')}:")
        print(f"   {i18n.t('current_value')}: {config.wavespeed_model}")
        print(f"\n   {i18n.t('image_to_image')}")
        print("      [1] google/nano-banana-pro/edit")
        print(f"         ‚Ä¢ {i18n.t('nano_banana_1')}")
        print(f"         ‚Ä¢ {i18n.t('nano_banana_2')}")
        print(f"         ‚Ä¢ {i18n.t('nano_banana_3')}")
        print(f"         ‚Ä¢ {i18n.t('nano_banana_4')}")
        print(f"         ‚Ä¢ {i18n.t('nano_banana_5')}")
        print(f"         ‚Ä¢ {i18n.t('nano_banana_6')}")
        print(f"\n      [2] bytedance/seedream-v4.5")
        print(f"         ‚Ä¢ {i18n.t('seedream_v45_1')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v45_2')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v45_3')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v45_4')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v45_5')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v45_6')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v45_7')}")
        print(f"\n      [3] bytedance/seedream-v4")
        print(f"         ‚Ä¢ {i18n.t('seedream_v4_1')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v4_2')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v4_3')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v4_4')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v4_5')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v4_6')}")
        print(f"         ‚Ä¢ {i18n.t('seedream_v4_7')}")
        print(f"\n   {i18n.t('image_to_video')}")
        print("      [4] alibaba/wan-2.5/image-to-video")
        print(f"         ‚Ä¢ {i18n.t('wan_25_1')}")
        print(f"         ‚Ä¢ {i18n.t('wan_25_2')}")
        print(f"         ‚Ä¢ {i18n.t('wan_25_3')}")
        print(f"\n      [5] kwaivgi/kling-v2.6-pro/image-to-video")
        print(f"         ‚Ä¢ {i18n.t('kling_v26_1')}")
        print(f"         ‚Ä¢ {i18n.t('kling_v26_2')}")
        print(f"         ‚Ä¢ {i18n.t('kling_v26_3')}")
        print(f"         ‚Ä¢ {i18n.t('kling_v26_4')}")
        print(f"\n      [6] kwaivgi/kling-v2.5-turbo-pro/image-to-video")
        print(f"         ‚Ä¢ {i18n.t('kling_v25_1')}")
        print(f"         ‚Ä¢ {i18n.t('kling_v25_2')}")
        print(f"         ‚Ä¢ {i18n.t('kling_v25_3')}")
        print(f"         ‚Ä¢ {i18n.t('kling_v25_4')}")
        choice = input("\n   –í–∞—à –≤—ã–±–æ—Ä (1-6 –∏–ª–∏ Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()
        models = {
            '1': 'google/nano-banana-pro/edit',
            '2': 'bytedance/seedream-v4.5',
            '3': 'bytedance/seedream-v4',
            '4': 'alibaba/wan-2.5/image-to-video',
            '5': 'kwaivgi/kling-v2.6-pro/image-to-video',
            '6': 'kwaivgi/kling-v2.5-turbo-pro/image-to-video'
        }
        if choice in models:
            config.wavespeed_model = models[choice]
            print(f"   ‚úì {i18n.t('selected')}: {config.wavespeed_model}")
        else:
            if config.wavespeed_model:
                print(f"   ‚Üí {i18n.t('using_value')}: {config.wavespeed_model}")
            else:
                print(f"   ‚ö†Ô∏è  {i18n.t('wavespeed_model')} {i18n.t('not_selected')}! {i18n.t('select_option')}.")
                # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å –µ—Å–ª–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞
                while not config.wavespeed_model:
                    choice = input(f"   {i18n.t('your_choice')} (1-6, {i18n.t('must_select')}): ").strip()
                    if choice in models:
                        config.wavespeed_model = models[choice]
                        print(f"   ‚úì {i18n.t('selected')}: {config.wavespeed_model}")
                    else:
                        print(f"   ‚ö†Ô∏è  {i18n.t('please_select_1_or_2')} (1-6)")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Wavespeed
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –¥–ª—è Nano Banana Pro –∏ Seedream –º–æ–¥–µ–ª–µ–π
        if 'edit' in config.wavespeed_model or 'seedream' in config.wavespeed_model.lower():
            print("\n5Ô∏è‚É£  –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è Wavespeed:")
            print(f"   –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {config.wavespeed_resolution}")
            print("\n   [1] 1k (1024√ó1024 –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–µ)")
            print(f"       ‚úì {i18n.t('resolution_1k_1')}")
            print(f"       ‚úì {i18n.t('resolution_1k_2')}")
            print(f"       ‚úì {i18n.t('resolution_1k_3')}")
            print(f"       ‚ö†Ô∏è  {i18n.t('resolution_1k_4')}")
            print(f"       üí° {i18n.t('resolution_1k_5')}")
            print("\n   [2] 2k (2048√ó2048 –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–µ)")
            print(f"       ‚úì {i18n.t('resolution_2k_1')}")
            print(f"       ‚úì {i18n.t('resolution_2k_2')}")
            print(f"       ‚úì {i18n.t('resolution_2k_3')}")
            print(f"       üí° {i18n.t('resolution_2k_4')}")
            print("\n   [3] 4k (4096√ó4096 –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–µ)")
            print(f"       ‚úì {i18n.t('resolution_4k_1')}")
            print(f"       ‚úì {i18n.t('resolution_4k_2')}")
            print(f"       ‚ö†Ô∏è  {i18n.t('resolution_4k_3')}")
            print(f"       ‚ö†Ô∏è  {i18n.t('resolution_4k_4')}")
            print(f"       üí° {i18n.t('resolution_4k_5')}")
            choice = input(f"\n   {i18n.t('your_choice')} (1-3 {i18n.t('or')} {i18n.t('press_enter_to_skip')}): ").strip()
            resolutions = {'1': '1k', '2': '2k', '3': '4k'}
            if choice in resolutions:
                config.wavespeed_resolution = resolutions[choice]
                print(f"   ‚úì {i18n.t('selected')}: {config.wavespeed_resolution}")
            else:
                print(f"   ‚Üí {i18n.t('using_value')} –∏–∑ config: {config.wavespeed_resolution}")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ captions (LoRA)
    print(f"\n6Ô∏è‚É£  {i18n.t('caption_generation')}:")
    current_generate = i18n.t('yes') if config.generate_captions else i18n.t('no')
    print(f"   {i18n.t('current_value')}: {current_generate}")
    print(f"\n   {i18n.t('caption_generation_desc')}")
    print(f"\n   [1] {i18n.t('caption_generation_yes')}")
    print(f"       ‚úì {i18n.t('caption_yes_1')}")
    print(f"       ‚úì {i18n.t('caption_yes_2')}")
    print(f"       ‚úì {i18n.t('caption_yes_3')}")
    print(f"       ‚ö†Ô∏è  {i18n.t('caption_yes_4')}")
    print(f"       ‚ö†Ô∏è  {i18n.t('caption_yes_5')}")
    print(f"       üí° {i18n.t('caption_yes_6')}")
    print(f"\n   [2] {i18n.t('caption_generation_no')}")
    print(f"       ‚úì {i18n.t('caption_no_1')}")
    print(f"       ‚úì {i18n.t('caption_no_2')}")
    print(f"       üí° {i18n.t('caption_no_3')}")
    choice = input(f"\n   {i18n.t('your_choice')} (1/2 {i18n.t('or')} {i18n.t('press_enter_to_skip')}): ").strip()
    if choice == '1':
        config.generate_captions = True
        print(f"   ‚úì {i18n.t('caption_enabled')}")
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º trigger name
        print(f"\n7Ô∏è‚É£  {i18n.t('trigger_name_prompt')}:")
        current_trigger = config.trigger_name if config.trigger_name else i18n.t('not_selected')
        print(f"   {i18n.t('current_value')}: {current_trigger}")
        print(f"\n   {i18n.t('trigger_name_desc')}")
        print(f"   {i18n.t('trigger_name_examples')}")
        print(f"   ‚ö†Ô∏è  {i18n.t('trigger_name_warning')}")
        trigger_input = input(f"\n   {i18n.t('enter')} trigger name ({i18n.t('or')} {i18n.t('press_enter_to_skip')}): ").strip()
        if trigger_input:
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            trigger_name = trigger_input.replace(' ', '_').replace('-', '_')
            config.trigger_name = trigger_name
            print(f"   ‚úì {i18n.t('trigger_name_set', name=trigger_name)}")
        else:
            if config.trigger_name:
                print(f"   ‚Üí {i18n.t('using_value')} –∏–∑ config: {config.trigger_name}")
            else:
                print(f"   ‚ö†Ô∏è  {i18n.t('trigger_name_not_set')}")
                config.generate_captions = False
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ OpenAI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ captions
        if config.generate_captions:
            print(f"\n8Ô∏è‚É£  {i18n.t('openai_caption_model')}:")
            current_caption_model = getattr(config, 'openai_caption_model', None) or config.openai_model or "gpt-5.1"
            print(f"   {i18n.t('current_value')}: {current_caption_model}")
            print("\n   [1] gpt-5.1")
            print(f"       ‚úì {i18n.t('gpt51_caption_1')}")
            print(f"       ‚úì {i18n.t('gpt51_caption_2')}")
            print(f"       ‚úì {i18n.t('gpt51_caption_3')}")
            print(f"       ‚úì {i18n.t('gpt51_caption_4')}")
            print(f"       ‚úì {i18n.t('gpt51_caption_5')}")
            print(f"\n   [2] gpt-4o ({i18n.t('gpt4o_caption_1')})")
            print(f"       ‚úì {i18n.t('gpt4o_caption_1')}")
            print(f"       ‚úì {i18n.t('gpt4o_caption_2')}")
            print(f"       ‚úì {i18n.t('gpt4o_caption_3')}")
            print(f"       ‚úì {i18n.t('gpt4o_caption_4')}")
            print(f"       ‚úì {i18n.t('gpt4o_caption_5')}")
            print(f"\n   ‚ö†Ô∏è  {i18n.t('caption_models_note')}")
            choice = input(f"\n   {i18n.t('your_choice')} (1-2 {i18n.t('or')} {i18n.t('press_enter_to_skip')}): ").strip()
            models = {
                '1': 'gpt-5.1',
                '2': 'gpt-4o'
            }
            if choice in models:
                config.openai_caption_model = models[choice]
                print(f"   ‚úì {i18n.t('selected')}: {config.openai_caption_model}")
            else:
                if hasattr(config, 'openai_caption_model') and config.openai_caption_model:
                    print(f"   ‚Üí {i18n.t('using_value')} –∏–∑ config: {config.openai_caption_model}")
                else:
                    config.openai_caption_model = 'gpt-5.1'
                    print(f"   ‚Üí {i18n.t('using_value')} –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {config.openai_caption_model}")
    elif choice == '2':
        config.generate_captions = False
        print(f"   ‚úì {i18n.t('caption_disabled')}")
    else:
        if config.generate_captions:
            print(f"   ‚Üí {i18n.t('using_value')} –∏–∑ config: {i18n.t('yes') if config.generate_captions else i18n.t('no')}")
            if config.generate_captions and not config.trigger_name:
                print(f"   ‚ö†Ô∏è  {i18n.t('trigger_name_warning_caption')}")
    
    i18n = get_i18n()
    print("\n" + "="*60)
    print(f"  ‚úÖ {i18n.t('settings_selected')}")
    print("="*60)
    print(f"\nüìã {i18n.t('final_settings')}")
    print(f"   {i18n.t('ai_provider')}: {config.ai_provider}")
    print(f"   {i18n.t('prompt_template')}: {config.prompt_template}")
    print(f"   {i18n.t('image_generation_provider')}: {config.image_provider}")
    if config.image_provider == 'wavespeed':
        print(f"   {i18n.t('wavespeed_model')}: {config.wavespeed_model}")
    if config.generate_captions:
        print(f"   {i18n.t('caption_generation')}: {i18n.t('yes')}")
        print(f"   {i18n.t('trigger_name')}: {config.trigger_name if config.trigger_name else i18n.t('not_selected')}")
        caption_model = getattr(config, 'openai_caption_model', None) or config.openai_model or 'gpt-5.1'
        print(f"   {i18n.t('openai_caption_model')}: {caption_model}")
    else:
        print(f"   {i18n.t('caption_generation')}: {i18n.t('no')}")
    print("\n")
    
    return config


def select_language():
    """–í—ã–±–æ—Ä —è–∑—ã–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    if not I18N_AVAILABLE:
        return
    
    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —è–∑—ã–∫ –∏–∑ config.json
    try:
        if os.path.exists('config.json'):
            with open('config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                lang = config.get('language', '').lower()
                if lang in ['ru', 'en']:
                    set_language(lang)
                    return
    except:
        pass
    
    # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤—ã–±—Ä–∞—Ç—å —è–∑—ã–∫
    print("=" * 60)
    print("  üåç Select Language / –í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫")
    print("=" * 60)
    print("\n[1] English")
    print("[2] –†—É—Å—Å–∫–∏–π")
    print("\n[Enter] Use default (Russian) / –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–†—É—Å—Å–∫–∏–π)")
    
    choice = input("\nYour choice / –í–∞—à –≤—ã–±–æ—Ä (1/2 –∏–ª–∏ Enter): ").strip()
    
    if choice == '1':
        set_language('en')
        print("‚úì Language set to English")
    elif choice == '2':
        set_language('ru')
        print("‚úì –Ø–∑—ã–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: –†—É—Å—Å–∫–∏–π")
    else:
        set_language('ru')
        print("‚Üí –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —è–∑—ã–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –†—É—Å—Å–∫–∏–π")
    
    print()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –í—ã–±–æ—Ä —è–∑—ã–∫–∞ –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ
    select_language()
    
    parser = argparse.ArgumentParser(
        description='Dataset Creation Bulk - Python –∞–Ω–∞–ª–æ–≥ Make.com workflow'
    )
    parser.add_argument(
        '--config',
        type=str,
        default='config.json',
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: config.json)'
    )
    parser.add_argument(
        '--profile',
        type=str,
        help='–ò–º—è –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –≤—ã–±–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è)'
    )
    parser.add_argument(
        '--ai-provider',
        choices=['gemini', 'openai'],
        help='AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç config)'
    )
    parser.add_argument(
        '--image-provider',
        choices=['wavespeed'],
        help='–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç config)'
    )
    parser.add_argument(
        '--interactive',
        '-i',
        action='store_true',
        help='–ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –º–µ–Ω—é –¥–ª—è –≤—ã–±–æ—Ä–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫'
    )
    parser.add_argument(
        '--no-interactive',
        action='store_true',
        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –º–µ–Ω—é (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ config –∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã)'
    )
    parser.add_argument(
        '--list-profiles',
        action='store_true',
        help='–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –∏ –≤—ã–π—Ç–∏'
    )
    
    args = parser.parse_args()
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Ñ–∏–ª–µ–π –∏ –≤—ã–π—Ç–∏
    if args.list_profiles:
        i18n = get_i18n()
        config = Config(args.config)
        profiles = config.list_profiles()
        if profiles:
            print(f"\nüìã {i18n.t('found_profiles', count=len(profiles))}\n")
            for profile in profiles:
                desc = f" - {profile['description']}" if profile.get('description') else ""
                print(f"   ‚Ä¢ {profile['name']}{desc}")
        else:
            print(f"\nüìã {i18n.t('no_profiles_saved')}")
        return
    
    # –í—ã–±–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω --no-interactive –∏ –Ω–µ —É–∫–∞–∑–∞–Ω --profile)
    selected_profile = None
    if not args.no_interactive and not args.profile:
        try:
            selected_profile = select_or_create_profile()
        except KeyboardInterrupt:
            print("\n\n‚ùå –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return
        except Exception as e:
            print(f"\n‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –ø—Ä–æ—Ñ–∏–ª—è: {e}")
            print("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –ø—Ä–æ—Ñ–∏–ª—è...\n")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    if args.profile:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        try:
            config = Config(args.config, profile_name=args.profile)
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ—Ñ–∏–ª—å: {args.profile}")
        except FileNotFoundError:
            print(f"‚ùå –ü—Ä–æ—Ñ–∏–ª—å '{args.profile}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
    elif selected_profile:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        config = Config(args.config, profile_name=selected_profile)
    else:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–º–∏–Ω–∏–º–∞–ª—å–Ω—É—é)
        config = Config(args.config)
    
    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö
    if args.ai_provider:
        config.ai_provider = args.ai_provider
    if args.image_provider:
        config.image_provider = args.image_provider
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –º–µ–Ω—é (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω --no-interactive)
    if not args.no_interactive:
        if args.interactive or not any([args.ai_provider, args.image_provider, args.profile]):
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é –µ—Å–ª–∏ —è–≤–Ω–æ –∑–∞–ø—Ä–æ—à–µ–Ω–æ –∏–ª–∏ –µ—Å–ª–∏ –Ω–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
            try:
                config = interactive_menu(config)
                # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å (–µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π)
                if not selected_profile and not args.profile:
                    save_profile_menu(config)
            except KeyboardInterrupt:
                print("\n\n‚ùå –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                return
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º –º–µ–Ω—é: {e}")
                import traceback
                traceback.print_exc()
                print("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏...\n")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    if not config.ai_provider:
        print("‚ùå –û—à–∏–±–∫–∞: AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –≤—ã–±—Ä–∞–Ω")
        print("   –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –º–µ–Ω—é –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ --ai-provider")
        return
    
    if not config.image_provider:
        print("‚ùå –û—à–∏–±–∫–∞: –ü—Ä–æ–≤–∞–π–¥–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω")
        print("   –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –º–µ–Ω—é –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ --image-provider")
        return
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    creator = DatasetCreator(config)
    creator.process_dataset()


if __name__ == '__main__':
    main()

